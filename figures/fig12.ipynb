{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f72924a7",
   "metadata": {},
   "source": [
    "# Figure 12\n",
    "\n",
    "Correlations between normalized parameter residuals from the synthetic retrieval experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f55e592",
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import ascii_lowercase as abc\n",
    "\n",
    "import cmcrameri.cm as cmc\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from lizard.mpltools import style\n",
    "from lizard.writers.figure_to_file import write_figure\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "from si_clouds.io.readers.ancillary import read_ancillary_data\n",
    "from si_clouds.io.readers.oem_result import read_oem_result_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab16fe74",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_anc = read_ancillary_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a48369",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_a_amb, ds_op_amb, _, ds_syn_amb = read_oem_result_concat(\n",
    "    version=\"pub_r2_syn_amb_v1\", test_id=\"random\", write=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee612c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_a_amb, ds_op_amb, ds_syn_amb = xr.align(\n",
    "    ds_a_amb, ds_op_amb, ds_syn_amb, join=\"inner\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3457f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# overview of some statistics for these simulations\n",
    "print(ds_anc.era5_tcwv.sel(time=ds_a_amb.time).mean(\"time\").item())\n",
    "print(ds_anc.era5_tcwv.sel(time=ds_a_amb.time).std(\"time\").item())\n",
    "print(ds_anc.era5_tcwv.sel(time=ds_a_amb.time).quantile(0.25, \"time\").item())\n",
    "print(ds_anc.era5_tcwv.sel(time=ds_a_amb.time).quantile(0.75, \"time\").item())\n",
    "\n",
    "print(ds_anc.era5_skt.sel(time=ds_a_amb.time).mean(\"time\").item() - 273.15)\n",
    "print(ds_anc.era5_skt.sel(time=ds_a_amb.time).std(\"time\").item())\n",
    "print(\n",
    "    ds_anc.era5_skt.sel(time=ds_a_amb.time).quantile(0.25, \"time\").item()\n",
    "    - 273.15\n",
    ")\n",
    "print(\n",
    "    ds_anc.era5_skt.sel(time=ds_a_amb.time).quantile(0.75, \"time\").item()\n",
    "    - 273.15\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0a5f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ds_op_amb.dgf.mean(\"time\"))\n",
    "print(ds_op_amb.dgf.median(\"time\"))\n",
    "print(ds_op_amb.dgf.quantile(0.25, \"time\"))\n",
    "print(ds_op_amb.dgf.quantile(0.75, \"time\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3296294",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute correlations from covariance matrix\n",
    "da_variance_1 = ds_op_amb.unc_aposteriori.sel(\n",
    "    update=ds_op_amb.conv_i,\n",
    "    x_vars1=ds_op_amb.x_vars1,\n",
    "    x_vars2=ds_op_amb.x_vars1,\n",
    ")\n",
    "da_variance_2 = ds_op_amb.unc_aposteriori.sel(\n",
    "    update=ds_op_amb.conv_i,\n",
    "    x_vars1=ds_op_amb.x_vars2,\n",
    "    x_vars2=ds_op_amb.x_vars2,\n",
    ")\n",
    "da_corr = ds_op_amb.unc_aposteriori.sel(update=ds_op_amb.conv_i) / np.sqrt(\n",
    "    da_variance_1 * da_variance_2\n",
    ")\n",
    "da_corr = da_corr.mean(\"time\")\n",
    "da_corr.where(np.abs(da_corr) > 0.1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63075e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "xb_vars = np.append(ds_op_amb.x_vars.values, ds_op_amb.b_vars.values)\n",
    "for v in ds_a_amb.b_vars.values:\n",
    "    ds_a_amb[v + \"_std\"] = np.sqrt(\n",
    "        ds_a_amb.unc_b.sel(b_vars1=v, b_vars2=v).mean(\"time\")\n",
    "    )\n",
    "\n",
    "print(\"Number of parameters:\", len(xb_vars))\n",
    "\n",
    "i = 0\n",
    "done = []\n",
    "x1_lst = []\n",
    "x2_lst = []\n",
    "xb_var1_lst = []\n",
    "xb_var2_lst = []\n",
    "corr_lst = []\n",
    "for xb_var1 in xb_vars:\n",
    "    for xb_var2 in xb_vars:\n",
    "        if xb_var1 == xb_var2:\n",
    "            continue\n",
    "        if (\n",
    "            xb_var1 in ds_op_amb.b_vars.values\n",
    "            and xb_var2 in ds_op_amb.b_vars.values\n",
    "        ):\n",
    "            continue\n",
    "        if xb_var1 + xb_var2 in done:\n",
    "            continue\n",
    "\n",
    "        if xb_var1 in ds_op_amb.x_vars.values:\n",
    "            x1 = (ds_op_amb[xb_var1] - ds_syn_amb[xb_var1]) / ds_a_amb[\n",
    "                xb_var1 + \"_std\"\n",
    "            ]\n",
    "        elif xb_var1 in ds_op_amb.b_vars.values:\n",
    "            x1 = (ds_a_amb[xb_var1] - ds_syn_amb[xb_var1]) / ds_a_amb[\n",
    "                xb_var1 + \"_std\"\n",
    "            ]\n",
    "\n",
    "        if xb_var2 in ds_op_amb.x_vars.values:\n",
    "            x2 = (ds_op_amb[xb_var2] - ds_syn_amb[xb_var2]) / ds_a_amb[\n",
    "                xb_var2 + \"_std\"\n",
    "            ]\n",
    "        elif xb_var2 in ds_op_amb.b_vars.values:\n",
    "            x2 = (ds_a_amb[xb_var2] - ds_syn_amb[xb_var2]) / ds_a_amb[\n",
    "                xb_var2 + \"_std\"\n",
    "            ]\n",
    "\n",
    "        # change x and y axis for negative correlations for easier plot reading\n",
    "        corr = pearsonr(x1.values, x2.values)[0]\n",
    "        corr_lst.append(corr)\n",
    "        x1_lst.append(x1)\n",
    "        x2_lst.append(x2)\n",
    "        xb_var1_lst.append(xb_var1)\n",
    "        xb_var2_lst.append(xb_var2)\n",
    "\n",
    "        done.append(xb_var1 + xb_var2)\n",
    "        done.append(xb_var2 + xb_var1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11f3bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = {\n",
    "    \"t_as\": r\"$T_{as}$\",\n",
    "    \"t_si\": r\"$T_{si}$\",\n",
    "    \"depth_hoar_corr_length\": r\"$\\xi_{DH}$\",\n",
    "    \"depth_hoar_density\": r\"$\\rho_{DH}$\",\n",
    "    \"depth_hoar_thickness\": r\"$h_{DH}$\",\n",
    "    \"wind_slab_corr_length\": r\"$\\xi_{WS}$\",\n",
    "    \"wind_slab_density\": r\"$\\rho_{WS}$\",\n",
    "    \"wind_slab_thickness\": r\"$h_{WS}$\",\n",
    "    \"yi_fraction\": r\"$f_{yi}$\",\n",
    "    \"cwp\": r\"CWP\",\n",
    "    \"specularity\": r\"$s$\",\n",
    "}\n",
    "\n",
    "cmap = cmc.berlin\n",
    "norm = mcolors.BoundaryNorm(np.arange(-1, 1.01, 0.2), cmap.N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efce6a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.1\n",
    "\n",
    "fig, axes = plt.subplots(\n",
    "    4, 4, figsize=(5, 5), layout=\"constrained\", sharex=True, sharey=True\n",
    ")\n",
    "\n",
    "for i, ax in enumerate(axes.flat[:-2]):\n",
    "    j = i % 4  # column index\n",
    "    k = i // 4  # row index (letter)\n",
    "    ax.annotate(\n",
    "        f\"({abc[k]}{j+1})\",\n",
    "        xy=(1, 1),\n",
    "        xycoords=\"axes fraction\",\n",
    "        ha=\"right\",\n",
    "        va=\"top\",\n",
    "        color=\"k\",\n",
    "    )\n",
    "\n",
    "i_ax = 0\n",
    "for i in np.argsort(corr_lst)[::-1]:\n",
    "    if abs(corr_lst[i]) < threshold:\n",
    "        continue\n",
    "\n",
    "    ax = axes.flat[i_ax]\n",
    "    im = ax.scatter(\n",
    "        x1_lst[i],\n",
    "        x2_lst[i],\n",
    "        c=np.repeat(corr_lst[i], len(x1_lst[i])),\n",
    "        s=1,\n",
    "        lw=0,\n",
    "        cmap=cmap,\n",
    "        norm=norm,\n",
    "    )\n",
    "\n",
    "    label = labels[xb_var1_lst[i]] + \"~\" + labels[xb_var2_lst[i]]\n",
    "\n",
    "    ax.annotate(\n",
    "        label,\n",
    "        xy=(0.5, 1),\n",
    "        xycoords=\"axes fraction\",\n",
    "        ha=\"center\",\n",
    "        va=\"bottom\",\n",
    "    )\n",
    "\n",
    "    # annotate the correlation\n",
    "    ax.annotate(\n",
    "        f\"{round(corr_lst[i], 2):.2f}\",\n",
    "        xy=(1, 0),\n",
    "        xycoords=\"axes fraction\",\n",
    "        ha=\"right\",\n",
    "        va=\"bottom\",\n",
    "    )\n",
    "\n",
    "    i_ax += 1\n",
    "\n",
    "for ax in axes.flat:\n",
    "    ax.set_ylim(-3, 3)\n",
    "    ax.set_xlim(-3, 3)\n",
    "    ax.set_aspect(\"equal\")\n",
    "    ax.set_xticks(np.arange(-3, 4, 2))\n",
    "    ax.set_yticks(np.arange(-3, 4, 2))\n",
    "    ax.set_xticklabels([rf\"{i}$\\sigma$\" for i in np.arange(-3, 4, 2)])\n",
    "    ax.set_yticklabels([rf\"{i}$\\sigma$\" for i in np.arange(-3, 4, 2)])\n",
    "    ax.grid()\n",
    "\n",
    "axes[-1, -2].set_axis_off()\n",
    "axes[-1, -1].set_axis_off()\n",
    "\n",
    "axes[-1, 0].set_xlabel(\"Norm. res.\")\n",
    "axes[-1, 0].set_ylabel(\"Norm. res.\")\n",
    "\n",
    "plt.draw()\n",
    "cax = fig.add_axes(\n",
    "    (\n",
    "        axes[-2, -2].get_position().x0,\n",
    "        axes[-1, -2].get_position().y1 - 0.04,\n",
    "        axes[-2, -1].get_position().x1 - axes[-2, -2].get_position().x0,\n",
    "        0.02,\n",
    "    )\n",
    ")\n",
    "fig.colorbar(\n",
    "    im, cax=cax, label=\"Correlation coefficient\", orientation=\"horizontal\"\n",
    ")\n",
    "\n",
    "write_figure(fig, f\"paper/fig12.png\", dpi=300, bbox_inches=\"tight\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
